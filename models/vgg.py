from typing import cast, Dict, List, Union

import torch
from torch import Tensor
from torch import nn

vgg_cfgs: Dict[str, List[Union[str, int]]] = {
    "vgg11": [64, "M", 128, "M", 256, 256, "M", 512, 512, "M", 512, 512, "M"],
    "vgg13": [64, 64, "M", 128, 128, "M", 256, 256, "M", 512, 512, "M", 512, 512, "M"],
    "vgg16": [64, 64, "M", 128, 128, "M", 256, 256, 256, "M", 512, 512, 512, "M", 512, 512, 512, "M"],
    "vgg19": [64, 64, "M", 128, 128, "M", 256, 256, 256, 256, "M", 512, 512, 512, 512, "M", 512, 512, 512, 512, "M"],
}


def _make_layers(vgg_cfg: List[Union[str, int]], batch_norm: bool = False, in_channels : int = 3) -> nn.Sequential:
    layers = []
    for v in vgg_cfg:
        if v == "M":
            layers.append(nn.MaxPool2d((2, 2), (2, 2)))
        else:
            v = cast(int, v)
            conv2d = nn.Conv2d(in_channels, v, (3, 3), (1, 1), (1, 1))
            if batch_norm:
                layers.append(conv2d)
                layers.append(nn.BatchNorm2d(v))
                layers.append(nn.ReLU(True))
            else:
                layers.append(conv2d)
                layers.append(nn.ReLU(True))
            in_channels = v

    return nn.Sequential(*layers)


class VGG(nn.Module):
    def __init__(self, margs = "11", dataset="cifar10", num_classes: int = 1000) -> None:
        super(VGG, self).__init__()
        
        """
        margs example: "11" or "11-bn"
        """

        margs = margs.split("-")
        self.vgg_id = "vgg"+margs[0]
        self.batch_norm = True if "bn" in margs else False
        if self.vgg_id not in vgg_cfgs:
            raise ValueError(f"Invalid config. Valid options are {list(vgg_cfgs.keys())}")
        vgg_cfg = vgg_cfgs[self.vgg_id]
        
        if(dataset == "cifar10"):
            self.in_channels = 3
        elif(dataset == "mnist"):
            self.in_channels = 1

        self.features = _make_layers(vgg_cfg, self.batch_norm, self.in_channels)

        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))

        self.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(True),
            nn.Dropout(0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(0.5),
            nn.Linear(4096, num_classes),
        )

        # Initialize neural network weights
        self._initialize_weights()

    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)

    # Support torch.script function
    def _forward_impl(self, x: Tensor) -> Tensor:
        out = self.features(x)
        out = self.avgpool(out)
        out = torch.flatten(out, 1)
        out = self.classifier(out)

        return out

    def _initialize_weights(self) -> None:
        for module in self.modules():
            if isinstance(module, nn.Conv2d):
                nn.init.kaiming_normal_(module.weight, mode="fan_out", nonlinearity="relu")
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm2d):
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.Linear):
                nn.init.normal_(module.weight, 0, 0.01)
                nn.init.constant_(module.bias, 0)
    
    def get_unique_id(self):
        if self.batch_norm:
            return f"vgg-{self.vgg_id}-bn"
        else:
            return f"vgg-{self.vgg_id}"